{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15c93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2c4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80dd7ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>film_name</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n                      Jean Reno denince zate...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n                      Ekşın falan izlemek is...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n                      Bu yapım hakkında öyle...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n                      finali yeter... (sting...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n                      Jean Reno..\\r\\nbu adam...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment      film_name point\n",
       "0  \\n                      Jean Reno denince zate...  Sevginin Gücü   5,0\n",
       "1  \\n                      Ekşın falan izlemek is...  Sevginin Gücü   5,0\n",
       "2  \\n                      Bu yapım hakkında öyle...  Sevginin Gücü   5,0\n",
       "3  \\n                      finali yeter... (sting...  Sevginin Gücü   5,0\n",
       "4  \\n                      Jean Reno..\\r\\nbu adam...  Sevginin Gücü   5,0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"turkish_movie_sentiment_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa173ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Jean Reno denince zaten leon filmi gelir akla ...\n",
       "1    Ekşın falan izlemek istiyorsanız eğer bunu izl...\n",
       "2    Bu yapım hakkında öyle çok şey yazabilirim ki ...\n",
       "3    finali yeter... (sting - shape of my heart)\\r\\...\n",
       "4    Jean Reno..\\r\\nbu adam kusursuz biri..\\r\\nve o...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = lambda x : x[23:-24]\n",
    "\n",
    "df[\"comment\"] = df[\"comment\"].apply(comments)\n",
    "df[\"comment\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f048a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    27463\n",
       "5.0    15873\n",
       "3.0    14494\n",
       "2.0    13866\n",
       "1.0     6381\n",
       "0.0     5150\n",
       "Name: point, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floatize = lambda x : float(x[0:-2])\n",
    "\n",
    "df[\"point\"] = df[\"point\"].apply(floatize)\n",
    "df[\"point\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed99636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    43336\n",
       "0.0    25397\n",
       "Name: point, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[df[\"point\"] == 3].index, inplace = True)\n",
    "df[\"point\"] = df[\"point\"].replace(1, 0)\n",
    "df[\"point\"] = df[\"point\"].replace(2, 0)\n",
    "df[\"point\"] = df[\"point\"].replace(4, 1)\n",
    "df[\"point\"] = df[\"point\"].replace(5, 1)\n",
    "df[\"point\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a46f0a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>film_name</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jean Reno denince zaten leon filmi gelir akla ...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ekşın falan izlemek istiyorsanız eğer bunu izl...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bu yapım hakkında öyle çok şey yazabilirim ki ...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finali yeter... (sting - shape of my heart)\\r\\...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jean Reno..\\r\\nbu adam kusursuz biri..\\r\\nve o...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment      film_name  point\n",
       "0  Jean Reno denince zaten leon filmi gelir akla ...  Sevginin Gücü    1.0\n",
       "1  Ekşın falan izlemek istiyorsanız eğer bunu izl...  Sevginin Gücü    1.0\n",
       "2  Bu yapım hakkında öyle çok şey yazabilirim ki ...  Sevginin Gücü    1.0\n",
       "3  finali yeter... (sting - shape of my heart)\\r\\...  Sevginin Gücü    1.0\n",
       "4  Jean Reno..\\r\\nbu adam kusursuz biri..\\r\\nve o...  Sevginin Gücü    1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace = True)\n",
    "df.drop(\"index\", axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce174b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>film_name</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jean reno denince zaten leon filmi gelir akla ...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ekşın falan izlemek istiyorsanız eğer bunu izl...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bu yapım hakkında öyle çok şey yazabilirim ki ...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finali yeter... (sting - shape of my heart)\\r\\...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jean reno..\\r\\nbu adam kusursuz biri..\\r\\nve o...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment      film_name  point\n",
       "0  jean reno denince zaten leon filmi gelir akla ...  Sevginin Gücü    1.0\n",
       "1  ekşın falan izlemek istiyorsanız eğer bunu izl...  Sevginin Gücü    1.0\n",
       "2  bu yapım hakkında öyle çok şey yazabilirim ki ...  Sevginin Gücü    1.0\n",
       "3  finali yeter... (sting - shape of my heart)\\r\\...  Sevginin Gücü    1.0\n",
       "4  jean reno..\\r\\nbu adam kusursuz biri..\\r\\nve o...  Sevginin Gücü    1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"comment\"] = df[\"comment\"].apply(lambda x: x.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e9ddcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>film_name</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jean reno denince zaten leon filmi gelir akla ...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ekşın falan izlemek istiyorsanız eğer bunu izl...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bu yapım hakkında öyle çok şey yazabilirim ki ...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finali yeter sting  shape of my heart    bazıl...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jean reno  bu adam kusursuz biri  ve oyunculug...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment      film_name  point\n",
       "0  jean reno denince zaten leon filmi gelir akla ...  Sevginin Gücü    1.0\n",
       "1  ekşın falan izlemek istiyorsanız eğer bunu izl...  Sevginin Gücü    1.0\n",
       "2  bu yapım hakkında öyle çok şey yazabilirim ki ...  Sevginin Gücü    1.0\n",
       "3  finali yeter sting  shape of my heart    bazıl...  Sevginin Gücü    1.0\n",
       "4  jean reno  bu adam kusursuz biri  ve oyunculug...  Sevginin Gücü    1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punc = [words for words in text if words not in string.punctuation]\n",
    "    word_wo_punc = \"\".join(no_punc)\n",
    "    return word_wo_punc\n",
    "\n",
    "df[\"comment\"] = df[\"comment\"].apply(lambda x: remove_punctuation(x))\n",
    "df[\"comment\"] = df[\"comment\"].apply(lambda x: x.replace(\"\\r\", \" \"))\n",
    "df[\"comment\"] = df[\"comment\"].apply(lambda x: x.replace(\"\\n\", \" \"))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3966c310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>film_name</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jean reno denince zaten leon filmi gelir akla ...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ekşın falan izlemek istiyorsanız eğer bunu izl...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bu yapım hakkında öyle çok şey yazabilirim ki ...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finali yeter sting  shape of my heart    bazıl...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jean reno  bu adam kusursuz biri  ve oyunculug...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment      film_name  point\n",
       "0  jean reno denince zaten leon filmi gelir akla ...  Sevginin Gücü    1.0\n",
       "1  ekşın falan izlemek istiyorsanız eğer bunu izl...  Sevginin Gücü    1.0\n",
       "2  bu yapım hakkında öyle çok şey yazabilirim ki ...  Sevginin Gücü    1.0\n",
       "3  finali yeter sting  shape of my heart    bazıl...  Sevginin Gücü    1.0\n",
       "4  jean reno  bu adam kusursuz biri  ve oyunculug...  Sevginin Gücü    1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_numeric(corpus):\n",
    "    output = \"\".join(words for words in corpus if not words.isdigit())\n",
    "    return output\n",
    "\n",
    "df[\"comment\"] = df[\"comment\"].apply(lambda x: remove_numeric(x)) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17ff9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"point\"].values.tolist()\n",
    "data = df[\"comment\"].values.tolist()\n",
    "\n",
    "cutoff = int(len(data)*0.80)\n",
    "\n",
    "X_train, X_test = data[:cutoff], data[cutoff:]\n",
    "y_train, y_test = target[:cutoff], target[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54be7bc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.keras.preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\4234939722.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.preprocessing'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33a9acf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.preprcessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\1171830391.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprcessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mToknizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.preprcessing'"
     ]
    }
   ],
   "source": [
    "from keras.preprcessing.text import Toknizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6d92a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "455712ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\3329015151.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words = num_words)\n",
    "tokenizer.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56a6831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f049a45",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.keras.preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\3587869311.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.preprocessing'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ed9550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8ee85d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Windows10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dfaa6ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.preprcessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\1241565162.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprcessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mToknizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.preprcessing'"
     ]
    }
   ],
   "source": [
    "from keras.preprcessing.text import Toknizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7517e16",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.keras.preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\1026293440.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.preprocessing'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ad2ca27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\1202024459.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m tf.keras.preprocessing.timeseries_dataset_from_array (\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msequence_stride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.preprocessing.timeseries_dataset_from_array (\n",
    "data,\n",
    "targets,\n",
    "sequence_length,\n",
    "sequence_stride = 2,\n",
    "sampling_rate = 1,\n",
    "end_index = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea04292d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\1997408649.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Tokenizer'"
     ]
    }
   ],
   "source": [
    "import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8a1c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8adeacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words = num_words)\n",
    "tokenizer.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2423713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film gerçekten bomba   çok komikti eğlenceli vakit geçirmek isteyen herkese öneririm  eddie murphy de gerçekten super oynamı']\n",
      "[3, 35, 3225, 5, 1857, 128, 202, 672, 872, 269, 1641, 3232, 3495, 7, 35, 1327, 8852]\n"
     ]
    }
   ],
   "source": [
    "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "print([X_train[1000]])\n",
    "print(X_train_tokens[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96214155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 47, 96, ..., 21,  4, 51])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = [len(tokens) for tokens in X_train_tokens + X_test_tokens]\n",
    "num_tokens = np.array(num_tokens)\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "281f4552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.318813379308338"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9f1e186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3094"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abe41ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + (2*np.std(num_tokens))\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d22ebf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9741754324705746"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efcee228",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pad_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\3647124627.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_pad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_pad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pad_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_pad = pad_sequences(X_train_tokens, maxlen = max_tokens) \n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen = max_tokens)\n",
    "\n",
    "print(X_train_pad.shape)\n",
    "print(X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd134a7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.keras.preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\337289045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.preprocessing'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d6fbd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11f5da91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41,   36, 1864,  416,   54, 1824,  480,  355,   80,   33])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_tokens[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e43205c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_pad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\326442096.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_pad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_pad' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_pad[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff44b7db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pad_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\3647124627.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_pad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_pad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pad_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_pad = pad_sequences(X_train_tokens, maxlen = max_tokens) \n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen = max_tokens)\n",
    "\n",
    "print(X_train_pad.shape)\n",
    "print(X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ce60875",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (C:\\Users\\Windows10\\anaconda4\\lib\\site-packages\\keras\\preprocessing\\sequence.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\355481930.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (C:\\Users\\Windows10\\anaconda4\\lib\\site-packages\\keras\\preprocessing\\sequence.py)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55adecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbc9d6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54986, 141)\n",
      "(13747, 141)\n"
     ]
    }
   ],
   "source": [
    "X_train_pad = pad_sequences(X_train_tokens, maxlen = max_tokens) \n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen = max_tokens)\n",
    "\n",
    "print(X_train_pad.shape)\n",
    "print(X_test_pad.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4971d12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41,   36, 1864,  416,   54, 1824,  480,  355,   80,   33])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_tokens[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0dc4ecc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    5,   70,    1,    3,    4,\n",
       "       5061, 4071,  851,    5,    5,   16,  527, 2370, 1105])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "467948c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))\n",
    "\n",
    "def tokens_to_string(tokens):\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    text = \" \".join(words) # Kelimeler aralarında boşluk bırakılarak ard arda yazılacaktır.\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c5c02f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bence gayet güzel bi filmdi her ne kadar kendi dışına yinede bence mükemmel bi oyunculuk ama her seyrettiğimde ayrı güzel bu filmide korku kategorisine hayret ettim doğrusu ne'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(X_train_tokens[350])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db1441da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12824\\3317576749.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0membedding_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"embedding_layer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Embedding' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_size = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = num_words, output_dim = embedding_size, input_length = max_tokens, name = \"embedding_layer\"))\n",
    "model.add(GRU(units = 16, return_sequences = True))\n",
    "model.add(GRU(units = 8, return_sequences = True))\n",
    "model.add(GRU(units = 4))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "856ae1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, GRU, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e573c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = num_words, output_dim = embedding_size, input_length = max_tokens, name = \"embedding_layer\"))\n",
    "model.add(GRU(units = 16, return_sequences = True))\n",
    "model.add(GRU(units = 8, return_sequences = True))\n",
    "model.add(GRU(units = 4))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "133f228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_layer (Embedding)  (None, 141, 50)          500000    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 141, 16)           3264      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 141, 8)            624       \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 4)                 168       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 504,061\n",
      "Trainable params: 504,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows10\\anaconda4\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr = 1e-3)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04c0f690",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (3787247319.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Windows10\\AppData\\Local\\Temp\\ipykernel_12824\\3787247319.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    model.fit(X_train_pad, y_train, epochs = 5, batch_size = 25\u001b[0m\n\u001b[1;37m                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "X_train_pad = np.array(X_train_pad)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model.fit(X_train_pad, y_train, epochs = 5, batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98100ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 71s 285ms/step - loss: 0.5296 - accuracy: 0.7570\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 68s 316ms/step - loss: 0.4053 - accuracy: 0.8334\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 72s 333ms/step - loss: 0.3666 - accuracy: 0.8553\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 68s 316ms/step - loss: 0.3403 - accuracy: 0.8722\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 68s 315ms/step - loss: 0.3148 - accuracy: 0.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2142fd0e520>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad = np.array(X_train_pad)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model.fit(X_train_pad, y_train, epochs = 5, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4aea848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_pad[0:1000])\n",
    "y_pred = y_pred.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ab58e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array([1.0 if p > 0.5 else 0.0 for p in y_pred])\n",
    "cls_true = np.array(y_test[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0be5c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array([1.0 if p > 0.5 else 0.0 for p in y_pred])\n",
    "cls_true = np.array(y_test[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "090634d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "267aa4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37c3ba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hayatımda izlediğim en yapmacık film gidip boşuna zaman kaybettim gitmek isteyen arkadaşlara tavsiyem teletabiler daha keyif'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = incorrect[10]\n",
    "X_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad2aac14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51791024"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb7ac635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_true[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d57b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
